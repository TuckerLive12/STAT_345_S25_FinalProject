---
title: "Final Project"
author: "Jack Kucera, Tanner Meighan, Adam Rafique"
date: "`r Sys.Date()`"
output: html_document
---

### Final Project Description

**General advice:** Get started early. If you wait to the last minute, it will not go well. For this project, you may find yourself spending a reasonable amount of time _searching_ for help.

1. _Maps_ The US Census Bureau provides mapping shape files for a variety of variables across the entire United States. You can explore these at [https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html](https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html). Make a map that displays county boundaries for the entire United States. You may use whichever package for plotting that you'd like, though you might find the 'ggmap' and 'rdgal' packages (and related tutorials) informative here.

2. _Roads_ Your goal in this step is to summarize (tabulate) the road suffixes for each county in the United States. County-level data can be found at [https://www2.census.gov/geo/tiger/TIGER2023/ROADS/](https://www2.census.gov/geo/tiger/TIGER2023/ROADS/). There are over 3000 files here, with file names that include the 5-digit GEOID for the county. As you process this data, you'll need to manage your memory in R. You'll likely want to download the file, unzip it, read it, summarize it, and then remove the file from memory. This is a great place for a function! Be sure to include the GEOID in your summary data for the next step.

3. _Putting it Together_ Merge the county shape files with your county-level summaries. The main plot to create for the project is to color your map from step 1 based on the most common road suffix (summary from step 2). Beyond this plot, feel free to be creative when making at least two additional plots.


#### Our work


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())

# Libraries
library(tidyverse)
library(foreign)
library(tigris)
library(usethis) # GitHub
library(gitcreds) # GitHub

# GitHub
#usethis::use_git_config(user.name = "TuckerLive12", user.email = "Jack.kucera@me.com")
#usethis::create_github_token()
#credentials::set_github_pat("yourPAT")
#gitcreds::gitcreds_set()
```

### Outline

Part 1: Create a map US counties (tanner)

- Create a map US counties



Part 2: tabulate (create a table) the road suffixes for each county in the United States. (Adam)

 - This invokes memory management and over 3000 files
 
 - Check all files for information (Jack?)
    - Create a small legend for each file in the folder form website and what it contains (potentially ask Dr. Baumann) in case we need other information.
    - Create a function that scrapes the website (https://www2.census.gov/geo/tiger/TIGER2023/ROADS/) for all the zip files, unzips them, and takes the file we want and put in into a folder in repository. (Jack)
      - DO NOT HAVE TO SCRAPE. can use roads() for all data.
    - Create a function that goes through each file and scrapes the suffixes from the address while keeping the ID of that address 
    - Find a pattern for finding the suffixes (Adam)
    - Create a function to find suffixes and put into a tibble with ID (Adam)
    - Create a function that matches the Id with county
 - Create table 

Part 3:

  - Create suffix divided by county plot
  - Addition Plot: A spatially contrained ... (Jack)








# Functions

```{r}

```

# Jack's Work

## Code

```{r Jack Kucera}
Alabama_Roads_2023 <- read_csv("./Data_Scraping_and_Database/Alabama_Roads_2023.csv", col_types = cols(LINEARID = "c"))

# Number of roads per county
Alabama_Roads_2023 |>
  count(STATE_ID,COUNTY_ID) |>
  mutate(Num_Roads = n, .keep = "unused") |>
  arrange(COUNTY_ID) 

# Columns of file
glimpse(Alabama_Roads_2023)

# Size of file
print("")
Alabama_Roads_2023 |>
  object.size() |>
  format(units = "auto")
```
### Comments

```{r}
# line 20-45 I want this to be a function 
```

# Tanners's Work

# Code

```{r Tanner}
library(ggplot2)
library(sf)
library(tigris)

options(tigris_use_cache = TRUE)


counties <- counties(cb = TRUE, resolution = "20m", year = 2024)  


 b = ggplot(data = counties) +
  geom_sf(fill = "white", color = "black", size = 0.1) +
  theme_minimal() +
  labs(title = "County Boundaries of the United States") +
  theme(
    axis.text = element_blank(),
    axis.ticks = element_blank(),
    panel.grid = element_blank()
  )
 ggsave("us_county_map.png", plot = b, width = 32, height = 20, dpi = 600)
 print(b)
 ## map with every county
```

### Comments

```{r}

```

# Adam's Work

## Code

```{r Adam}


#use ?tigris to pull up the github page with the descriptions of all the functions, use those functions to create the list of road suffixes

#We could have a function that goes through the list of state and county FIPS codes (STATEFP & COUNTYFP) in the counties table and gives the list of roads in that particular county. We could make it a loop that opens a particular road dataset, allows us to collect the required data, then removes the dataset from the environment so we can do it again for the next dataset.

counties <- counties(cb = TRUE) #Enters the list of counties into R's memory

#Generates the random sample
sample <- sample.int(nrow(counties), 10, replace = FALSE)

#Creates the dataframe that the road data will be placed into. For now, it is designed with the intent of creating a random sample because trying to do it for the entire nation would take too long. I've tried. FIPSCode is there to make filtering the territories out of the data easier. We could keep it in the dataframe for this exact purpose.
Compilation <- data.frame(StateID = counties$STATEFP[sample[1]], CountyID = counties$COUNTYFP[sample[1]], No = 1, State = counties$STATE_NAME[sample[1]], County = counties$NAME[sample[1]])

for(i in 2:length(sample)) {
  Compilation <- rbind(Compilation, list(counties$STATEFP[sample[i]], counties$COUNTYFP[sample[i]], i, counties$STATE_NAME[sample[i]], counties$NAME[sample[i]]))
}

#Filters out the territories. There is no FIPS Code 59, the state with the highest FIPS code is Wyoming at 58, the territory with the lowest FIPS Code is American Samoa at 60.
Compilation <- filter(Compilation, StateID < 60)

#Main loop that compiles the data for the number of each type of suffix by county. This is supposed to go up to the number of rows in the counties table, but doing it for all counties takes too long so I decided to make it go up to 10 and pick counties at random instead.

for (i in 1:nrow(Compilation)) {
  
  #Pulls the index for the county whose data will be pulled. Apparently county FIPS codes aren't unique between states, and I've found an instance where two counties have the same name and the same FIPS code (Alleghany County, Virginia and Alleghany County, North Carolina)
  j <- which(counties$COUNTYFP == Compilation$CountyID[i] & counties$STATE_NAME == Compilation$State[i])
  print(j)
  
  #Inputs the road data for the county in question. STATEFP is the state FPIS and COUNTYFP is the county FPIS
  RoadData <- roads(counties$STATEFP[j], counties$COUNTYFP[j])
  
  #These two lines use a regular expression to separate the suffix from the rest of the name.
  RoadData$Suffix <- str_extract(RoadData$FULLNAME, "[:upper:]{1}[:lower:]{0,3}(?:-|\\ )?[:digit:]{0,}$")
  RoadData$Suffix <- str_extract(RoadData$Suffix, "^[:upper:]{1}[:lower:]{0,3}")
  
  #Replaces N/A road suffixes
  RoadData$Suffix <- replace(RoadData$Suffix, is.na(RoadData$Suffix), "Not Applicable")
  
  #Removes N/A road names
  RoadData <- na.omit(RoadData)
  
  repeat {#Finds the number of times each suffix appears in RoadData and adds it to the dataframe
    
    #Adds the number to the column in the appropriate row if there's already a column for the suffix
    if (RoadData$Suffix[1] %in% names(Compilation)) {
      Compilation[[RoadData$Suffix[1]]][i] <- nrow(RoadData[RoadData$Suffix == RoadData$Suffix[1],])
    }
    
    #Creates a new column if there isn't already a column for the suffix
    else { 
      
      #Creates a temporary variable to store the suffix until it can be made the new column's name. Anything more direct than        this approach that I've tried just produces an error
      x <- RoadData$Suffix[1]
      
      #0 is a placeholder value and newRow is a temporary name. I've found that both are necessary to prevent errors.
      Compilation$newCol <- 0
      
      #For whatever reason, the comma at the end is necessary to make sure the code works properly
      Compilation$newCol[i] <- nrow(RoadData[RoadData$Suffix == RoadData$Suffix[1],])
      
      #Changes the column name to the suffix
      names(Compilation)[names(Compilation) == 'newCol'] <- x
    }
    #Removes the suffix from the data
    RoadData <- RoadData %>% filter(Suffix != Suffix[1])
    
    #Ends the while loop once all the data has been accounted for
    if (nrow(RoadData) == 0) {break}
  }
  
  #Removes RoadData from the environment so we can start again
  remove(RoadData)
}

```

## Comments

```{r}


# Removes as rows where FULLNAME has na. extracts the suffix from FULLNAME and put into new column called SUFFIX. If SUFFIX is na, replaces it with "Not Applicable".
dat1 <- Alabama_Roads_2023 |>
  filter(!is.na(FULLNAME)) |>
  mutate(SUFFIX = str_extract(FULLNAME, "[:upper:]{1}[:lower:]{0,3}(?:-|\\ )?[:digit:]{0,}$")) |>
  mutate(SUFFIX = str_extract(SUFFIX, "^[:upper:]{1}[:lower:]{0,3}")) |>
  mutate(SUFFIX = replace(SUFFIX, is.na(SUFFIX), "Not Applicable")) |>
  filter(!(SUFFIX == "Not Applicable")) |>
  group_by(COUNTY_ID) |>
  count(SUFFIX) |>
  slice_max(n, n = 1, with_ties = FALSE)

bind_rows(dat, dat1)


# Shows the highest suffix count for each county, ignores the "Not Applicable" Suffixes.
Alabama_Roads_2023 |>
  filter(!(SUFFIX == "Not Applicable")) |>
  group_by(COUNTY_ID, STATE_ID) |>
  count(SUFFIX) |>
  slice_max(n, n = 1, with_ties = FALSE) |>
  print()

############
# Create a for loop that goes through each states .csv file and extracts the highest suffix count for each county. combine the highest suffix count into one tibble, keep STATE_ID, COUNTY_ID, SUFFIX, and n (count). I suggest you do this one at a time.  
##########

file_location <- "./Data_Scraping_and_Database/TOREPLACE_Roads_2023.csv"

str_replace(file_location, Regular_expression, list[1])

states <- c(
  "Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", 
  "Delaware", "Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", 
  "Kansas", "Kentucky", "Louisiana", "Maine", "Maryland", "Massachusetts", "Michigan", 
  "Minnesota", "Mississippi", "Missouri", "Montana", "Nebraska", "Nevada", "NewHampshire", 
  "NewJersey", "NewMexico", "NewYork", "NorthCarolina", "NorthDakota", "Ohio", 
  "Oklahoma", "Oregon", "Pennsylvania", "RhodeIsland", "SouthCarolina", "SouthDakota", 
  "Tennessee", "Texas", "Utah", "Vermont", "Virginia", "Washington", "WestVirginia", 
  "Wisconsin", "Wyoming"
)



```

