---
title: "Final Project"
author: "Jack Kucera, Tanner Meighan, Adam Rafique"
date: "`r Sys.Date()`"
output: html_document
---

### Final Project Description

**General advice:** Get started early. If you wait to the last minute, it will not go well. For this project, you may find yourself spending a reasonable amount of time _searching_ for help.

1. _Maps_ The US Census Bureau provides mapping shape files for a variety of variables across the entire United States. You can explore these at [https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html](https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html). Make a map that displays county boundaries for the entire United States. You may use whichever package for plotting that you'd like, though you might find the 'ggmap' and 'rdgal' packages (and related tutorials) informative here.

2. _Roads_ Your goal in this step is to summarize (tabulate) the road suffixes for each county in the United States. County-level data can be found at [https://www2.census.gov/geo/tiger/TIGER2023/ROADS/](https://www2.census.gov/geo/tiger/TIGER2023/ROADS/). There are over 3000 files here, with file names that include the 5-digit GEOID for the county. As you process this data, you'll need to manage your memory in R. You'll likely want to download the file, unzip it, read it, summarize it, and then remove the file from memory. This is a great place for a function! Be sure to include the GEOID in your summary data for the next step.

3. _Putting it Together_ Merge the county shape files with your county-level summaries. The main plot to create for the project is to color your map from step 1 based on the most common road suffix (summary from step 2). Beyond this plot, feel free to be creative when making at least two additional plots.


#### Our work


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())

source("./Data_Scraping_and_Database/Data Scraping.R")

# Libraries
library(tidyverse)
library(ggwordcloud)
library(foreign)
library(tigris)
library(usethis) # GitHub
library(gitcreds) # GitHub

#system("git fetch origin")
#system("git reset --hard origin/main")

# GitHub
#usethis::use_git_config(user.name = "TuckerLive12", user.email = "Jack.kucera@me.com")
#usethis::create_github_token()
#credentials::set_github_pat("yourPAT")
#gitcreds::gitcreds_set()
```

### Outline

Part 1: Create a map US counties (tanner)

- Create a map US counties



Part 2: tabulate (create a table) the road suffixes for each county in the United States. (Adam)

 - This invokes memory management and over 3000 files
 
 - Check all files for information (Jack?)
    - Create a small legend for each file in the folder form website and what it contains (potentially ask Dr. Baumann) in case we need other information.
    - Create a function that scrapes the website (https://www2.census.gov/geo/tiger/TIGER2023/ROADS/) for all the zip files, unzips them, and takes the file we want and put in into a folder in repository. (Jack)
      - DO NOT HAVE TO SCRAPE. can use roads() for all data.
    - Create a function that goes through each file and scrapes the suffixes from the address while keeping the ID of that address 
    - Find a pattern for finding the suffixes (Adam)
    - Create a function to find suffixes and put into a tibble with ID (Adam)
    - Create a function that matches the Id with county
 - Create table 

Part 3:

  - Create suffix divided by county plot
  - Addition Plot: A spatially contrained ... (Jack)








# Functions

```{r}

```

# Jack's Work

## Code

```{r Jack Kucera}
Alabama_Roads_2023_Backup <- read_csv("./Data_Scraping_and_Database/Alabama_Roads_2023.csv", col_types = cols(LINEARID = "c"))

# Number of roads per county
Alabama_Roads_2023_Backup |>
  count(STATE_ID,COUNTY_ID) |>
  mutate(Num_Roads = n, .keep = "unused") |>
  arrange(COUNTY_ID) 

# Columns of file
glimpse(Alabama_Roads_2023_Backup)

# Size of file
print("")
Alabama_Roads_2023_Backup |>
  object.size() |>
  format(units = "auto")
```
### Comments

```{r}
# line 20-45 I want this to be a function 
```

# Tanners's Work

# Code

```{r Tanner}
library(ggplot2)
library(sf)
library(tigris)

options(tigris_use_cache = TRUE)


counties <- counties(cb = TRUE, resolution = "20m", year = 2023)  

states = states(cb = TRUE, resolution = "20m", year = 2023)

 b = ggplot(data = counties) +
  geom_sf(fill = "white", color = "black", size = 0.1) +
  theme_minimal() +
  labs(title = "County Boundaries of the United States") +
  theme(
    axis.text = element_blank(),
    axis.ticks = element_blank(),
    panel.grid = element_blank(),
    plot.margin = margin(l = 0, r = -33, t = 0, b = -2, unit = "cm")
  )
 ggsave("us_county_map.png", plot = b, width = 32, height = 20, dpi = 600)
 print(b)
 ## map with every county
```

### Comments

```{r}

```

# Adam's Work

###
# Important, I'm going to change COUNTY_ID to COUNTYFP for consististy. 
##

## Code

```{r Adam}
# I changed this so that we can have the top 5 most frequent suffixes



#use ?tigris to pull up the github page with the descriptions of all the functions, use those functions to create the list of road suffixes

#We could have a function that goes through the list of state and county FIPS codes (STATEFP & COUNTYFP) in the counties table and gives the list of roads in that particular county. We could make it a loop that opens a particular road dataset, allows us to collect the required data, then removes the dataset from the environment so we can do it again for the next dataset.

# counties <- counties(cb = TRUE, year = 2023) #Enters the list of counties into R's memory

Filepaths <- get_state_filepaths("Data_Scraping_and_Database/ToReplace_Roads_2023.csv")

#Compilation <- data.frame(COUNTYFP = counties$COUNTYFP, STATE_ID = counties$STATEFP, MOSTFREQUENT = rep("Placeholder", nrow(counties)), N = rep(0, nrow(counties))) |>
  #mutate(COUNTYFP = as.numeric(COUNTYFP)) |>
  #mutate(STATE_ID = as.numeric(STATE_ID)) |>
  #Filters out territories and DC. The territories all have STATE_ID values that are 60 or higher and DC has a STATE_ID of 11
  #filter(STATE_ID < 60 & STATE_ID != 11)

Compilation <- read_csv(Filepaths$file_path[1]) |>
    mutate(COUNTYFP = as.numeric(COUNTYFP)) |>
    mutate(STATE_ID = as.numeric(STATE_ID)) |>
    filter(!is.na(FULLNAME)) |>
    mutate(SUFFIX = str_extract(FULLNAME, "[:upper:]{1}[:lower:]{0,3}(?:-|\\ )?[:digit:]{0,}$")) |>
    mutate(SUFFIX = str_extract(SUFFIX, "^[:upper:]{1}[:lower:]{0,3}")) |>
    filter(!is.na(SUFFIX)) |>
    group_by(COUNTYFP, STATE_ID) |>
    count(SUFFIX)

for (i in 2:50) {
  data <- read_csv(Filepaths$file_path[i], col_types = "c",) |>
    mutate(COUNTYFP = as.numeric(COUNTYFP)) |>
    mutate(STATE_ID = as.numeric(STATE_ID)) |>
    filter(!is.na(FULLNAME)) |>
    mutate(SUFFIX = str_extract(FULLNAME, "[:upper:]{1}[:lower:]{0,3}(?:-|\\ )?[:digit:]{0,}$")) |>
    mutate(SUFFIX = str_extract(SUFFIX, "^[:upper:]{1}[:lower:]{0,3}")) |>
    filter(!is.na(SUFFIX)) |>
    group_by(COUNTYFP, STATE_ID) |>
    count(SUFFIX)
  
  # Helpful print out
  print(paste0("Extracting state ", Filepaths$state[i]))
  
  Compilation <- bind_rows(Compilation, data)
  
  data <- NULL
  
  
}
gc()
```

## Comments

```{r}
Compilation1 <- Compilation |>
  group_by(STATE_ID, COUNTYFP) |>
  slice_max(n, n = 1, with_ties = FALSE) |>
  # Removes any most frequent suffix that's in less than 5 counties
  filter(!(SUFFIX %in% c("Ar", "Cir", "Cr", "Fs", "Gove", "K", "Lake", "Liv", "Lr", "P", "Pl", "Pvt", "R", "Road", "S", "Sfc", "T", "Trl", "Way"))) |>
  ungroup()

Compilation2 <- Compilation |>
  group_by(STATE_ID, COUNTYFP) |>
  slice_max(n, n = 2, with_ties = FALSE) |>
  slice_tail() |>
  filter(!(SUFFIX %in% c("A", "Aly", "Area", "C", "Cir", "Cs", "Cv", "Dade", "Ew", "Fr", "Lcr", "Lk", "Nc", "Ns", "Off", "P", "Pcr", "Pike", "Pl", "Pt", "Pvt", "R", "Road", "Run", "Sp", "Tc", "Ter", "Trl", "Usfs", "Ut", "Way"))) |>
  ungroup()

Compilation_States <- Compilation |>
  group_by(STATE_ID, SUFFIX) |>
  summarise(n = sum(n)) |>
  arrange(desc(n)) |>
  slice_max(n, n = 1, with_ties = FALSE) |>
  ungroup()


counties |>
  group_by(STATEFP) |>
  count(STATEFP)
```


# Maps 
```{r}
Compilation1 <- Compilation |>
  group_by(STATE_ID, COUNTYFP) |>
  slice_max(n, n = 1, with_ties = FALSE) |>
  # Removes any most frequent suffix thats in less than 5 counties
  filter(!(SUFFIX %in% c("Ar", "Cir", "Cr", "Fs", "Gove", "Hwy", "K", "Lake", "Liv", "Lr", "P", "Pl", "Pvt", "R", "Road", "Rte", "S", "Sfc", "T", "Trl", "Way")))


##rename certain columns so everything matches for joins
dat1 = Compilation1  #rename(dat1, COUNTYFP = COUNTY_ID)
dat1$COUNTYFP <- as.character(dat1$COUNTYFP)
dat1$STATE_ID <- as.character(dat1$STATE_ID)
dat1 <- rename(dat1, STATEFP = STATE_ID)

dat1

counties$COUNTYFP <- sub("^0+", "", counties$COUNTYFP)
counties$STATEFP <- sub("^0+", "", counties$STATEFP)

dat2 = inner_join(dat1, counties, by = c("COUNTYFP", "STATEFP"), )
dat2
##dat2 is a left join of counties filtered to Alabama(ala_counties) and dat 1 needed to adjust some variable names in order to join  
## re cast county id column in dat1. countyfp column in counties df are characters while county id are doubles 

dat2_plain <- dat2 %>% st_drop_geometry()


map_data <- left_join(counties, dat2_plain, by = "GEOID")
map_data
##wouldnt graph properly without above two lines 

c = ggplot(data = map_data) +
  geom_sf(aes(fill = SUFFIX), color = "black", size = 0.1) +
  theme_minimal() +
  labs(
    title = "Most Common Road Suffix by County",
    fill = "Road Suffix"
  ) + ##change title for full map
  theme(
    axis.text = element_blank(),
    axis.ticks = element_blank(),
    panel.grid = element_blank(),
    panel.background = element_rect(fill = "white", color = NA),
    plot.background = element_rect(fill = "white", color = NA),
    legend.background = element_rect(fill = "white", color = NA),
    legend.box.background = element_rect(fill = "white", color = NA),
    plot.margin = margin(l = 0, r=-30, t=0, b=-2, unit = "cm"),
    legend.position = "left"
  )
ggsave("most_common_road_suffix_by_county.png", plot = c, width = 32, height = 20, dpi = 600)
print(c)

## map with every county

Compilation_States = Compilation_States %>% 
  rename(STATEFP = STATE_ID)
Compilation_States$STATEFP <- as.character(Compilation_States$STATEFP)
states$STATEFP <- sub("^0+", "", states$STATEFP)

Compilation_States2 = left_join(states, Compilation_States, by = "STATEFP")

d = ggplot(data = Compilation_States2) +
  geom_sf(aes(fill = SUFFIX), color = "black", size = 0.1) +
  theme_minimal() +
  labs(
    title = "Most Common Road Suffix by State",
    fill = "Road Suffix"
  ) + ##change title for full map
  theme(
    axis.text = element_blank(),
    axis.ticks = element_blank(),
    panel.grid = element_blank(),
    panel.background = element_rect(fill = "white", color = NA),
    plot.background = element_rect(fill = "white", color = NA),
    legend.background = element_rect(fill = "white", color = NA),
    legend.box.background = element_rect(fill = "white", color = NA),
    plot.margin = margin(l = 0, r=-30, t=0, b=-2, unit = "cm"),
    legend.position = "left"
  ) 
print(d)
ggsave("most_common_road_suffix_by_State.png", plot = d, width = 32, height = 20, dpi = 600)
```



```{r Testing Code}
# Function to help add commas to large numbers in graphs
add_commas <- function(x) {
  format(x, big.mark = ",", scientific = FALSE)
}

# Function help in graphs, converts a number 0-1.00 into percent form (eg. 0.27 -> 27%) 
to_percent <- function(x) {
  paste0(round(x * 100), "%")
}

Compilation |>
  group_by(STATE_ID, COUNTYFP) |>
  count(n())

Compilation |>
  group_by(SUFFIX) |>
  summarise(number_of_occurrences = sum(n)) |>
  arrange(desc(number_of_occurrences)) |>
  slice_max(number_of_occurrences, n = 50) |>
  ggplot(aes(x = reorder(SUFFIX, -number_of_occurrences), y = number_of_occurrences)) +
    geom_bar(stat = "identity", fill = "skyblue") +
    labs(x = "Suffix", y = "Number of Occurrences", title = "Top 50 Suffixes by Number of Occurrences in US Roads") +
    scale_y_continuous(limits = c(0, 2100000), breaks = seq(0, 2100000, by = 100000), labels = add_commas) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
      #panel.grid.major = element_blank(),
      panel.grid.minor = element_blank()
    )
  
Compilation |>
  group_by(SUFFIX) |>
  summarise(percent_of_occurrences = n()) |>
  arrange(desc(percent_of_occurrences)) 

Compilation |>
  group_by(SUFFIX) |>
  summarise(percent_of_occurrences = n()/3143) |>
  arrange(desc(percent_of_occurrences)) |>
  slice_max(percent_of_occurrences, n = 50) |>
  ggplot(aes(x = reorder(SUFFIX, -percent_of_occurrences), y = percent_of_occurrences)) +
    geom_bar(stat = "identity", fill = "skyblue") +
    labs(x = "Suffix", y = "Percent of Occurrences", title = "Top 50 Suffixes by Percent of Occurrences in US Counties") +
    scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.05), labels = to_percent) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
      #panel.grid.major = element_blank(),
      panel.grid.minor = element_blank()
    )

Compilation |>
  group_by(SUFFIX) |>
  summarise(number_of_occurrences = sum(n)) |>
  arrange(desc(number_of_occurrences)) |>
  slice_min(number_of_occurrences, n = 10) |>
  ggplot(aes(label = SUFFIX, size = number_of_occurrences, color = number_of_occurrences)) +
    geom_text_wordcloud() +
    scale_size_area(max_size = 10) +  # Adjust max size of words
    scale_color_gradient(low = "blue", high = "red") +  # Optional: color gradient based on frequency
    labs(title = "Word Cloud of Names by Frequency") +
    theme_minimal() 
    


```










```{r}


# Removes as rows where FULLNAME has na. extracts the suffix from FULLNAME and put into new column called SUFFIX. If SUFFIX is na, replaces it with "Not Applicable".
dat1 <- Alabama_Roads_2023_Backup |>
  filter(!is.na(FULLNAME)) |>
  mutate(SUFFIX = str_extract(FULLNAME, "[:upper:]{1}[:lower:]{0,3}(?:-|\\ )?[:digit:]{0,}$")) |>
  mutate(SUFFIX = str_extract(SUFFIX, "^[:upper:]{1}[:lower:]{0,3}")) |>
  mutate(SUFFIX = replace(SUFFIX, is.na(SUFFIX), "Not Applicable")) |>
  filter(!(SUFFIX == "Not Applicable")) |>
  group_by(COUNTY_ID) |>
  count(SUFFIX) |>
  slice_max(n, n = 1, with_ties = FALSE)

#bind_rows(dat, dat1)


# Shows the highest suffix count for each county, ignores the "Not Applicable" Suffixes.
#Alabama_Roads_2023_Backup |>
#  filter(!(SUFFIX == "Not Applicable")) |>
#  group_by(COUNTY_ID, STATE_ID) |>
#  count(SUFFIX) |>
#  slice_max(n, n = 1, with_ties = FALSE) |>
#  print()

dat1 <- Alabama_Roads_2023_Backup |>
  filter(!is.na(FULLNAME)) |>
  mutate(SUFFIX = str_extract(FULLNAME, "[:upper:]{1}[:lower:]{0,3}(?:-|\\ )?[:digit:]{0,}$")) |>
  mutate(SUFFIX = str_extract(SUFFIX, "^[:upper:]{1}[:lower:]{0,3}")) |>
  mutate(SUFFIX = replace(SUFFIX, is.na(SUFFIX), "Not Applicable")) |>
  filter(!(SUFFIX == "Not Applicable")) |>
  group_by(COUNTY_ID) |>
  count(SUFFIX) |>
  slice_max(n, n = 1, with_ties = FALSE)


```